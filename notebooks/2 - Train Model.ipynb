{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Romance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from math import exp\n",
    "import pickle\n",
    "from importlib import reload\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Input, Masking, BatchNormalization, Layer, Embedding\n",
    "from keras.layers import LSTM, Reshape, TimeDistributed, Concatenate, Multiply, RepeatVector\n",
    "from keras.optimizers import Nadam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change directory to project/parent directory\n",
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "helpers = reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHARS_SEQS_PATH = \"data/joke_char_sequences_Jan20.h5\"\n",
    "TOPICS_PATH = \"data/joke_topics.pkl\"\n",
    "TOPIC_MODELER_PATH = \"data/jokes_topic_modeler.pkl\"\n",
    "CHAR_DICT_PATH = \"data/char_dict_Jan20.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "#this is nubmer of 128 layers + 1 (there is layws at least one 127 (unit layers))\n",
    "\n",
    "#i wonder if lstm is necasry of gru woruld work\n",
    "MIDDLE_DEPTH=3\n",
    "SEQ_LENGTH = 300\n",
    "RESUME = True\n",
    "MODEL_NAME = \"rnn_jokes_topics_Jan25.hdf5\"\n",
    "#BASE_CELL_SIZE=64\n",
    "#should change to maybe max seq length...\n",
    "#for varios monitoring applications\n",
    "MONITOR_FREQ=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#easier to define here\n",
    "TOTAL_DEPTH = MIDDLE_DEPTH + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File(CHARS_SEQS_PATH, \"r\")\n",
    "seqs = h5f[\"seqs\"][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109095"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_seqs = seqs.shape[0]\n",
    "num_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344.61687520052584\n"
     ]
    }
   ],
   "source": [
    "#average length\n",
    "mean_length = 0.0\n",
    "for seq in seqs:\n",
    "    mean_length += len(seq)/num_seqs\n",
    "print(mean_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load char dict\n",
    "pickle_in = open(CHAR_DICT_PATH,\"rb\")\n",
    "char_dict = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "num_chars=len(char_dict)\n",
    "print(num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load encoder\n",
    "topic_modeler = joblib.load(TOPIC_MODELER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load topics\n",
    "topics = joblib.load(TOPICS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "topic_size = topics.shape[1]\n",
    "print(topic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['say',\n",
       "  'ask',\n",
       "  'prostitute',\n",
       "  'look',\n",
       "  'leper',\n",
       "  'tampon',\n",
       "  'reply',\n",
       "  'turn',\n",
       "  'stick',\n",
       "  'tip',\n",
       "  'blonde',\n",
       "  'fish',\n",
       "  'nice',\n",
       "  'think',\n",
       "  'little',\n",
       "  'pirate',\n",
       "  'boy',\n",
       "  'friend',\n",
       "  'thing',\n",
       "  'drive'],\n",
       " ['like',\n",
       "  'coffee',\n",
       "  'slave',\n",
       "  'penis',\n",
       "  'free',\n",
       "  'chocolate',\n",
       "  'life',\n",
       "  'dark',\n",
       "  'taste',\n",
       "  'smell',\n",
       "  'dick',\n",
       "  'food',\n",
       "  'look',\n",
       "  'humor',\n",
       "  'feel',\n",
       "  'box',\n",
       "  'lot',\n",
       "  'sound',\n",
       "  'beer',\n",
       "  'domestic'],\n",
       " ['joke',\n",
       "  'funny',\n",
       "  'punchline',\n",
       "  'dick',\n",
       "  'laugh',\n",
       "  'mom',\n",
       "  'bad',\n",
       "  'reddit',\n",
       "  'apparent',\n",
       "  'post',\n",
       "  'r',\n",
       "  'unemployed',\n",
       "  'work',\n",
       "  'chemistry',\n",
       "  'wanna',\n",
       "  'racist',\n",
       "  'title',\n",
       "  'long',\n",
       "  'want',\n",
       "  'execution'],\n",
       " ['lightbulb',\n",
       "  'change',\n",
       "  'feminist',\n",
       "  'screw',\n",
       "  'alzheimer',\n",
       "  'funny',\n",
       "  'dark',\n",
       "  'juan',\n",
       "  'mexicans',\n",
       "  'basement',\n",
       "  'patient',\n",
       "  'pregnant',\n",
       "  'room',\n",
       "  'number',\n",
       "  'germans',\n",
       "  'beat',\n",
       "  'efficient',\n",
       "  'optometrist',\n",
       "  'trick',\n",
       "  'dead'],\n",
       " ['bar',\n",
       "  'walk',\n",
       "  'bartender',\n",
       "  'drink',\n",
       "  'beer',\n",
       "  'serve',\n",
       "  'order',\n",
       "  'duck',\n",
       "  'ask',\n",
       "  'table',\n",
       "  'irishman',\n",
       "  'chair',\n",
       "  'past',\n",
       "  'bear',\n",
       "  'blonde',\n",
       "  'tense',\n",
       "  'termite',\n",
       "  'future',\n",
       "  'horse',\n",
       "  'roman'],\n",
       " ['knock',\n",
       "  'door',\n",
       "  'forget',\n",
       "  'prize',\n",
       "  'freedom',\n",
       "  'bell',\n",
       "  'mop',\n",
       "  'america',\n",
       "  'daisy',\n",
       "  'invent',\n",
       "  'ring',\n",
       "  'dish',\n",
       "  'sally',\n",
       "  'jehovah',\n",
       "  'favorite',\n",
       "  'alzheimer',\n",
       "  'interrupt',\n",
       "  'person',\n",
       "  'pencil',\n",
       "  'witness'],\n",
       " ['people',\n",
       "  'hate',\n",
       "  'world',\n",
       "  'type',\n",
       "  'fat',\n",
       "  'kind',\n",
       "  'die',\n",
       "  'threesome',\n",
       "  'talk',\n",
       "  'count',\n",
       "  'unemployed',\n",
       "  'mean',\n",
       "  'binary',\n",
       "  'condescend',\n",
       "  'work',\n",
       "  'understand',\n",
       "  'life',\n",
       "  'think',\n",
       "  'lot',\n",
       "  'chocolate'],\n",
       " ['man',\n",
       "  'reply',\n",
       "  'ask',\n",
       "  'park',\n",
       "  'old',\n",
       "  'warm',\n",
       "  'day',\n",
       "  'car',\n",
       "  'look',\n",
       "  'chinese',\n",
       "  'jewish',\n",
       "  'life',\n",
       "  'spaceman',\n",
       "  'second',\n",
       "  'fish',\n",
       "  'sit',\n",
       "  'rest',\n",
       "  'run',\n",
       "  'young',\n",
       "  'space'],\n",
       " ['difference',\n",
       "  's',\n",
       "  'dick',\n",
       "  'jesus',\n",
       "  'outlaw',\n",
       "  'mom',\n",
       "  'job',\n",
       "  'prostitute',\n",
       "  'snowman',\n",
       "  'hooker',\n",
       "  'porcupine',\n",
       "  'thermometer',\n",
       "  'picture',\n",
       "  'face',\n",
       "  'hitler',\n",
       "  'suck',\n",
       "  'feminist',\n",
       "  'ignorance',\n",
       "  'acne',\n",
       "  'irish'],\n",
       " ['hear',\n",
       "  'want',\n",
       "  'kidnapping',\n",
       "  'new',\n",
       "  'mexican',\n",
       "  'pencil',\n",
       "  'mathematician',\n",
       "  'work',\n",
       "  'calendar',\n",
       "  'wanna',\n",
       "  'steal',\n",
       "  'deaf',\n",
       "  'constipated',\n",
       "  'pterodactyl',\n",
       "  'wake',\n",
       "  'probably',\n",
       "  'hipster',\n",
       "  'hole',\n",
       "  'die',\n",
       "  'circus'],\n",
       " ['girlfriend',\n",
       "  'dump',\n",
       "  'cannibal',\n",
       "  'wipe',\n",
       "  'break',\n",
       "  'laugh',\n",
       "  'ex',\n",
       "  'imaginary',\n",
       "  'competitive',\n",
       "  'ass',\n",
       "  'think',\n",
       "  'fat',\n",
       "  'start',\n",
       "  'fit',\n",
       "  'homeless',\n",
       "  'clothe',\n",
       "  'smoke',\n",
       "  'relationship',\n",
       "  'pissed',\n",
       "  'slow'],\n",
       " ['dad',\n",
       "  'son',\n",
       "  'father',\n",
       "  'boy',\n",
       "  'mom',\n",
       "  'kid',\n",
       "  'ask',\n",
       "  'mother',\n",
       "  'reply',\n",
       "  'dollar',\n",
       "  'little',\n",
       "  'want',\n",
       "  'school',\n",
       "  'jewish',\n",
       "  'johnny',\n",
       "  'masturbate',\n",
       "  'daddy',\n",
       "  'adopt',\n",
       "  'daughter',\n",
       "  'parent'],\n",
       " ['make',\n",
       "  'atom',\n",
       "  'trust',\n",
       "  'water',\n",
       "  'boil',\n",
       "  'holy',\n",
       "  'hell',\n",
       "  'hebrew',\n",
       "  'hormone',\n",
       "  'moses',\n",
       "  'tea',\n",
       "  'ugly',\n",
       "  'day',\n",
       "  'tickle',\n",
       "  'money',\n",
       "  'pay',\n",
       "  'love',\n",
       "  'anal',\n",
       "  'hole',\n",
       "  'weak'],\n",
       " ['use',\n",
       "  'condom',\n",
       "  'word',\n",
       "  'steal',\n",
       "  'addict',\n",
       "  'teacher',\n",
       "  'bear',\n",
       "  'soap',\n",
       "  'clean',\n",
       "  'time',\n",
       "  'indecisive',\n",
       "  'goodyear',\n",
       "  'tire',\n",
       "  'bike',\n",
       "  'hand',\n",
       "  'common',\n",
       "  'hate',\n",
       "  'parachute',\n",
       "  'think',\n",
       "  'circumcision'],\n",
       " ['know',\n",
       "  'letter',\n",
       "  'alphabet',\n",
       "  'nose',\n",
       "  'ignorance',\n",
       "  'really',\n",
       "  'orphan',\n",
       "  'apathy',\n",
       "  'body',\n",
       "  'care',\n",
       "  'feel',\n",
       "  'baseball',\n",
       "  'number',\n",
       "  'play',\n",
       "  'ladder',\n",
       "  'shoe',\n",
       "  'drive',\n",
       "  'drug',\n",
       "  'lace',\n",
       "  'mean'],\n",
       " ['dog',\n",
       "  'leg',\n",
       "  'zoo',\n",
       "  'leave',\n",
       "  'labracadabrador',\n",
       "  'matter',\n",
       "  'cat',\n",
       "  'come',\n",
       "  'shitzu',\n",
       "  'bike',\n",
       "  'right',\n",
       "  'short',\n",
       "  'dyslexic',\n",
       "  'magic',\n",
       "  'arm',\n",
       "  'bleed',\n",
       "  'skydive',\n",
       "  'agnostic',\n",
       "  'night',\n",
       "  'little'],\n",
       " ['girl',\n",
       "  'date',\n",
       "  'boy',\n",
       "  'meet',\n",
       "  'little',\n",
       "  'ask',\n",
       "  'number',\n",
       "  'want',\n",
       "  'attractive',\n",
       "  'fat',\n",
       "  'today',\n",
       "  'home',\n",
       "  'damn',\n",
       "  'odd',\n",
       "  'drop',\n",
       "  'homeless',\n",
       "  'hey',\n",
       "  'night',\n",
       "  'tit',\n",
       "  'eventually'],\n",
       " ['sex',\n",
       "  'fuck',\n",
       "  'anal',\n",
       "  'time',\n",
       "  'life',\n",
       "  'oral',\n",
       "  'common',\n",
       "  'threesome',\n",
       "  'phone',\n",
       "  'camp',\n",
       "  'position',\n",
       "  'hole',\n",
       "  'object',\n",
       "  'tent',\n",
       "  'ask',\n",
       "  'weak',\n",
       "  'try',\n",
       "  'mate',\n",
       "  'number',\n",
       "  'chinese'],\n",
       " ['woman',\n",
       "  'ugly',\n",
       "  'husband',\n",
       "  'jewish',\n",
       "  'wrong',\n",
       "  'easy',\n",
       "  'time',\n",
       "  'pregnant',\n",
       "  'pick',\n",
       "  'coffee',\n",
       "  'driver',\n",
       "  'heavy',\n",
       "  'think',\n",
       "  'beautiful',\n",
       "  'love',\n",
       "  'ask',\n",
       "  'money',\n",
       "  'drive',\n",
       "  'baby',\n",
       "  'inch'],\n",
       " ['black',\n",
       "  'white',\n",
       "  'racist',\n",
       "  'afraid',\n",
       "  'cop',\n",
       "  'society',\n",
       "  'trump',\n",
       "  'paint',\n",
       "  'beat',\n",
       "  'police',\n",
       "  'shoot',\n",
       "  'fall',\n",
       "  'cruise',\n",
       "  'stair',\n",
       "  'person',\n",
       "  'work',\n",
       "  'mexican',\n",
       "  'room',\n",
       "  'batman',\n",
       "  'run'],\n",
       " ['cross',\n",
       "  'chicken',\n",
       "  'road',\n",
       "  'kill',\n",
       "  'door',\n",
       "  'egg',\n",
       "  'sedan',\n",
       "  'sock',\n",
       "  'wrong',\n",
       "  'coop',\n",
       "  'mexican',\n",
       "  'wear',\n",
       "  'potato',\n",
       "  'favorite',\n",
       "  'jesus',\n",
       "  'sperm',\n",
       "  'semen',\n",
       "  'diana',\n",
       "  'princess',\n",
       "  'titanic'],\n",
       " ['doctor',\n",
       "  'patient',\n",
       "  'bad',\n",
       "  'news',\n",
       "  'masturbate',\n",
       "  'stop',\n",
       "  'live',\n",
       "  'doc',\n",
       "  'ask',\n",
       "  'examine',\n",
       "  'alzheimer',\n",
       "  'problem',\n",
       "  'try',\n",
       "  'month',\n",
       "  'reply',\n",
       "  'exam',\n",
       "  'cancer',\n",
       "  'office',\n",
       "  'prostate',\n",
       "  'need'],\n",
       " ['good',\n",
       "  'thing',\n",
       "  'bad',\n",
       "  'really',\n",
       "  'tree',\n",
       "  'hide',\n",
       "  'elephant',\n",
       "  'friend',\n",
       "  'news',\n",
       "  'period',\n",
       "  'time',\n",
       "  'way',\n",
       "  'day',\n",
       "  'pun',\n",
       "  'ruin',\n",
       "  'piano',\n",
       "  'organ',\n",
       "  'miss',\n",
       "  's',\n",
       "  'rose'],\n",
       " ['cow',\n",
       "  'beef',\n",
       "  'leg',\n",
       "  'milk',\n",
       "  'ground',\n",
       "  'masturbate',\n",
       "  'mad',\n",
       "  'disease',\n",
       "  'jerky',\n",
       "  'hoof',\n",
       "  'farmer',\n",
       "  'field',\n",
       "  'stroganoff',\n",
       "  'udder',\n",
       "  'pms',\n",
       "  'count',\n",
       "  'abortion',\n",
       "  'birth',\n",
       "  'lactose',\n",
       "  'lip'],\n",
       " ['light',\n",
       "  'bulb',\n",
       "  'screw',\n",
       "  'change',\n",
       "  'hard',\n",
       "  'sleep',\n",
       "  'fly',\n",
       "  'optometrist',\n",
       "  'cop',\n",
       "  'room',\n",
       "  'heavy',\n",
       "  'zippo',\n",
       "  'alzheimer',\n",
       "  'hippo',\n",
       "  'beat',\n",
       "  'cigarette',\n",
       "  'blue',\n",
       "  'patient',\n",
       "  'dark',\n",
       "  'psychiatrist'],\n",
       " ['guy',\n",
       "  'come',\n",
       "  'gay',\n",
       "  'steal',\n",
       "  'think',\n",
       "  'calendar',\n",
       "  'second',\n",
       "  'hitler',\n",
       "  'look',\n",
       "  'drunk',\n",
       "  'happen',\n",
       "  'right',\n",
       "  'month',\n",
       "  'wish',\n",
       "  'hey',\n",
       "  'left',\n",
       "  'fuck',\n",
       "  'ask',\n",
       "  'kill',\n",
       "  'stop'],\n",
       " ['just',\n",
       "  'think',\n",
       "  'kid',\n",
       "  'work',\n",
       "  'today',\n",
       "  'job',\n",
       "  'day',\n",
       "  'word',\n",
       "  'new',\n",
       "  'lose',\n",
       "  'want',\n",
       "  'buy',\n",
       "  'really',\n",
       "  'break',\n",
       "  'trump',\n",
       "  'ice',\n",
       "  'need',\n",
       "  'car',\n",
       "  'plagiarism',\n",
       "  'watch'],\n",
       " ['tell',\n",
       "  'friend',\n",
       "  'laugh',\n",
       "  'ask',\n",
       "  'stop',\n",
       "  'time',\n",
       "  'vegan',\n",
       "  'worry',\n",
       "  'teacher',\n",
       "  'blonde',\n",
       "  'day',\n",
       "  'mean',\n",
       "  'high',\n",
       "  'boss',\n",
       "  'want',\n",
       "  'try',\n",
       "  'parent',\n",
       "  'surprised',\n",
       "  'eyebrow',\n",
       "  'draw'],\n",
       " ['eat',\n",
       "  'gay',\n",
       "  'horse',\n",
       "  'cannibal',\n",
       "  'vegetable',\n",
       "  'hard',\n",
       "  'wheelchair',\n",
       "  'lesbian',\n",
       "  'common',\n",
       "  'time',\n",
       "  'dinosaur',\n",
       "  'clock',\n",
       "  'shit',\n",
       "  'zombie',\n",
       "  'consume',\n",
       "  'pizza',\n",
       "  'fish',\n",
       "  'taste',\n",
       "  'vegetarian',\n",
       "  'food'],\n",
       " ['wife',\n",
       "  'husband',\n",
       "  'want',\n",
       "  'die',\n",
       "  'home',\n",
       "  'happy',\n",
       "  'ask',\n",
       "  'night',\n",
       "  'meet',\n",
       "  'leave',\n",
       "  'love',\n",
       "  'sleep',\n",
       "  'car',\n",
       "  'house',\n",
       "  'job',\n",
       "  'bed',\n",
       "  'fat',\n",
       "  'ex',\n",
       "  'honey',\n",
       "  'cheat'],\n",
       " ['year',\n",
       "  'old',\n",
       "  'come',\n",
       "  'santa',\n",
       "  'sack',\n",
       "  'lady',\n",
       "  'big',\n",
       "  'today',\n",
       "  'vision',\n",
       "  'happy',\n",
       "  'new',\n",
       "  'live',\n",
       "  'claus',\n",
       "  'ago',\n",
       "  'meet',\n",
       "  'time',\n",
       "  'common',\n",
       "  'kid',\n",
       "  'child',\n",
       "  'day'],\n",
       " ['blind',\n",
       "  'fall',\n",
       "  'german',\n",
       "  'hard',\n",
       "  'eye',\n",
       "  'table',\n",
       "  'chair',\n",
       "  'skydive',\n",
       "  'dinosaur',\n",
       "  'step',\n",
       "  'nudist',\n",
       "  'scar',\n",
       "  'lady',\n",
       "  'date',\n",
       "  'tree',\n",
       "  'prostitute',\n",
       "  'deer',\n",
       "  'beach',\n",
       "  'colony',\n",
       "  'spot']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get top words per topic\n",
    "topic_modeler.top_words(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharGenSequence(object):\n",
    "    def __init__(self, seqs, char_dict, topics, batch_size=500, seq_length=100):\n",
    "        self.seqs = seqs\n",
    "        self.char_dict = char_dict\n",
    "        #need to know how big input to neural net (length of sequnece)\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        #the  random permtuion returns a randomly sorted rangs\n",
    "        self.seq_idxs = deque(np.random.permutation(len(seqs)).tolist())\n",
    "        #now intitilize first batch\n",
    "        #these are the indexes of seq_list that are used for the batch.\n",
    "        #queu will help, can pop from left\n",
    "        self.batch_idxs = [self.seq_idxs.pop() for _ in range(self.batch_size)]\n",
    "        \n",
    "        #ALWAYS START AT BEGINNING...\n",
    "        self.seq_pos = [0 for seq in self.batch_idxs]\n",
    "        \n",
    "        #now topics\n",
    "        self.topics = topics\n",
    "        topic_dim = self.topics.shape[1]\n",
    "        \n",
    "        self.batch_topics = np.zeros((self.batch_size, topic_dim), dtype=np.float)\n",
    "        \n",
    "        #now fill\n",
    "        for ix, batch_idx in enumerate(self.batch_idxs):\n",
    "            self.batch_topics[ix, :] = self.topics[ix, :]\n",
    "        \n",
    "    def __next__(self):\n",
    "        #make masks\n",
    "        #used to determine if will use reset state or not...\n",
    "        #will rely on brtaod casting to gie ii th eproer shape\n",
    "        state_mask = np.ones((self.batch_size, 1), dtype=np.float32)\n",
    "        #make x, the input a numpy array of zeros (initilaly)\n",
    "        #nowing providing just indexes, since\n",
    "        x = np.zeros((self.batch_size, self.seq_length, len(self.char_dict)), dtype=np.float)\n",
    "        \n",
    "        #will use sparse categorical\n",
    "        y = np.zeros((self.batch_size, self.seq_length, 1), dtype=np.int32)\n",
    "        \n",
    "        #LOOP OVER BATCH\n",
    "        #seq_idx is the index of the sequnce within seq_list\n",
    "        #while batch_idx is the index of the sequence within the batch        \n",
    "        for batch_idx, seq_idx in enumerate(self.batch_idxs):\n",
    "            #work fowards...\n",
    "            #GO UP TO LENGTH OF OUTPUTS...\n",
    "            #check if this will be last batch for this input seq\n",
    "\n",
    "            for pos_idx in range(self.seq_length):\n",
    "                #self.seq_pos is start of sequence\n",
    "                input_pos_idx =  self.seq_pos[batch_idx]+pos_idx\n",
    "                #OUTPUTS ALWAYS ONE AHEAD OF INPUTS\n",
    "                output_pos_idx = input_pos_idx + 1\n",
    "                #if desired index does not exit, leave blank....\n",
    "                try:\n",
    "                    x[batch_idx, pos_idx, self.seqs[seq_idx][input_pos_idx]] = 1.\n",
    "                except IndexError:\n",
    "                    #leave at default of 0 (padding value)\n",
    "                    pass\n",
    "                try:\n",
    "                    y[batch_idx, pos_idx, 0] = self.seqs[seq_idx][output_pos_idx]\n",
    "                except IndexError:\n",
    "                    #will be masked anyways?\n",
    "                    y[batch_idx, pos_idx, 0] = self.char_dict[\"<BOUND>\"]\n",
    "        \n",
    "\n",
    "            #DO SPECIAL STUFF IF length of sequence is less than than what was desired...\n",
    "            if len(self.seqs[seq_idx]) <= (self.seq_length + self.seq_pos[batch_idx]):\n",
    "                #first add back to avaialbe\n",
    "                self.seq_idxs.append(self.batch_idxs[batch_idx])\n",
    "                \n",
    "                #pop left ensures first in, first out\n",
    "                self.batch_idxs[batch_idx] = self.seq_idxs.popleft()\n",
    "                    \n",
    "                #set start pos back to 0\n",
    "                self.seq_pos[batch_idx] = 0\n",
    "\n",
    "                #get new word_indxs and wghts\n",
    "                self.batch_topics[batch_idx, :] = self.topics[self.batch_idxs[batch_idx], :]\n",
    "                \n",
    "                #make masks = 0 to reset state\n",
    "                #could probaly do this outside of the generator...\n",
    "                state_mask[batch_idx,0] = 0.0\n",
    "            else:\n",
    "                #increment position by seq_length\n",
    "                #want last output character to be the first input character...\n",
    "                self.seq_pos[batch_idx]=self.seq_pos[batch_idx]+ self.seq_length\n",
    "        return(x, y, self.batch_topics, state_mask)\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ACTUAL\n",
    "gen_seq =  CharGenSequence(seqs, char_dict=char_dict, topics=topics, seq_length=SEQ_LENGTH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import sparse_softmax_cross_entropy_with_logits\n",
    "from helpers import WghtdAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this layer makes \n",
    "class Standardize(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Standardize, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def call(self, inputs, mask = None):\n",
    "        #first, mean of 0\n",
    "        inputs = inputs - K.mean(inputs, axis=-1, keepdims=True)\n",
    "        #now, want to induce a variacne of 1\n",
    "        inputs = inputs / (K.sqrt(K.mean(K.square(inputs), axis=-1, keepdims=True)) + K.epsilon())\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(batch_size, input_length, num_chars, rnn_depth=1, topic_size=32):\n",
    "    #character sequences\n",
    "    character_input = Input(batch_shape=(batch_size,input_length, num_chars), dtype='float', name='char_indx_input')\n",
    "    masked = Masking(name=\"mask\")(character_input)\n",
    "    #topic input\n",
    "    topic_input = Input(batch_shape=(batch_size, topic_size), dtype='float', name='topic_input')\n",
    "    topic = Standardize()(topic_input)\n",
    "    topic_repeated = RepeatVector(input_length, name=\"repeat_topic\")(topic)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #first, to get to 32\n",
    "    rnn =  LSTM(units=32,return_sequences=True, stateful=True, name=\"rnn0\")(masked)\n",
    "    rnn = sequences = BatchNormalization(name=\"normalize0\")(rnn)\n",
    "    #now 64\n",
    "    rnn =  LSTM(units=64,return_sequences=True, stateful=True, name=\"rnn1\")(rnn)\n",
    "    #now concatenate topic..\n",
    "    sequences = Concatenate(name=\"concatenate\")([rnn, topic_repeated])\n",
    "    sequences = BatchNormalization(name=\"normalize1\")(sequences)\n",
    "    \n",
    "    for i in range(rnn_depth):\n",
    "        rnn =  LSTM(units=128,return_sequences=True, stateful=True, name=\"rnn\"+str(i+2))(sequences)\n",
    "        sequences = BatchNormalization(name=\"normalize\"+str(i+2))(rnn)\n",
    "\n",
    "    #now 256 *maybe 512?\n",
    "    #should have argument...\n",
    "    rnn =  LSTM(units=256,return_sequences=True, stateful=True, name=\"rnn\"+str(rnn_depth+2))(sequences)\n",
    "    sequences = BatchNormalization(name=\"normalize\"+str(rnn_depth+2))(rnn)\n",
    "    rnn =  LSTM(units=512,return_sequences=True, stateful=True, name=\"rnn\"+str(rnn_depth+3))(sequences)\n",
    "        \n",
    "    preds = TimeDistributed(Dense(num_chars), name=\"logits\")(rnn)\n",
    "    model = Model(inputs=[character_input, topic_input], outputs=preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RESUME is not None:\n",
    "    #this might not work since last layer is a different size\n",
    "    #might have to load manually (for first...)\n",
    "    training_model = load_model(\"models/\"+MODEL_NAME, custom_objects={\"Standardize\":Standardize,\n",
    "                                                                     \"sparse_softmax_cross_entropy_with_logits\":sparse_softmax_cross_entropy_with_logits})\n",
    "    training_model.reset_states()\n",
    "else:\n",
    "    training_model = create_model(batch_size=BATCH_SIZE, input_length=SEQ_LENGTH, num_chars=num_chars,\n",
    "                              rnn_depth=MIDDLE_DEPTH, topic_size=topic_size)\n",
    "    training_model.compile(loss=sparse_softmax_cross_entropy_with_logits, optimizer=Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_indx_input (InputLayer)    (512, 300, 98)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (Masking)                  (512, 300, 98)       0           char_indx_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rnn0 (LSTM)                     (512, 300, 32)       16768       mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "topic_input (InputLayer)        (512, 32)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalize0 (BatchNormalization) (512, 300, 32)       128         rnn0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "standardize_1 (Standardize)     (512, 32)            0           topic_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn1 (LSTM)                     (512, 300, 64)       24832       normalize0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_topic (RepeatVector)     (512, 300, 32)       0           standardize_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (512, 300, 96)       0           rnn1[0][0]                       \n",
      "                                                                 repeat_topic[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "normalize1 (BatchNormalization) (512, 300, 96)       384         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn2 (LSTM)                     (512, 300, 128)      115200      normalize1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize2 (BatchNormalization) (512, 300, 128)      512         rnn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn3 (LSTM)                     (512, 300, 128)      131584      normalize2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize3 (BatchNormalization) (512, 300, 128)      512         rnn3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn4 (LSTM)                     (512, 300, 128)      131584      normalize3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize4 (BatchNormalization) (512, 300, 128)      512         rnn4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn5 (LSTM)                     (512, 300, 256)      394240      normalize4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize5 (BatchNormalization) (512, 300, 256)      1024        rnn5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn6 (LSTM)                     (512, 300, 512)      1574912     normalize5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "logits (TimeDistributed)        (512, 300, 98)       50274       rnn6[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 2,442,466\n",
      "Trainable params: 2,440,930\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make prediction model\n",
    "#should have a dunciotn that extrracts, num_chars, rnn_depth and topic size from trianing model\n",
    "#batch size of one, and only on time step\n",
    "predict_model = create_model(batch_size=1, input_length=1, num_chars=num_chars,\n",
    "                             rnn_depth=MIDDLE_DEPTH, topic_size=topic_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to sample an index from a probability array\n",
    "def sample(preds, end_indx, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    #is logged proability\n",
    "    #so exp(log(prob) / temperature) is smaller when temperature is higer\n",
    "    #however derivative respect to temp: -log(prob) /temperature^2\n",
    "    #-log(prob) is bigger when prob is smaller\n",
    "    #so result is that lower temp makes smaller probs go to 0 faster\n",
    "    preds = preds / temperature \n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEED TO PROVIDE A \"topic\"\n",
    "def generate_joke(model, topic, char_dict, max_len=1000, base_temp=0.5, temp_decay=0.1):\n",
    "    model.reset_states()\n",
    "    #prediction model only take \n",
    "    x_input = np.zeros((1,1, len(char_dict)), dtype =np.float32)\n",
    "    \n",
    "    #reverse the character dictionary, since will need to go from integer index to character\n",
    "    char_dict_reverse = {value:key for key, value in char_dict.items()}\n",
    "    #first input to the model will be the <BOUND> token\n",
    "    x_input[0,0, char_dict[\"<BOUND>\"]] = 1.0\n",
    "    #x_indxs is used to store output, ant thus to generate jokes\n",
    "    x_indxs = [char_dict[\"<BOUND>\"]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        #want a decreasing temperature\n",
    "        temperature= base_temp*exp(-i*temp_decay)\n",
    "        #want only first...\n",
    "        preds = model.predict_on_batch(x={\"char_indx_input\":x_input, \"topic_input\":topic})[0,0]\n",
    "        next_index = sample(preds, end_indx=char_dict[\"<BOUND>\"], temperature=1)\n",
    "        #only need to update first index, since stateful...\n",
    "        #make x_input again\n",
    "        x_input = np.zeros((1,1, len(char_dict)), dtype =np.float32)\n",
    "        x_input[0,0,next_index] = 1.0\n",
    "        #now append to list that is used for text genration...\n",
    "        x_indxs.append(next_index)\n",
    "        if next_index == char_dict[\"<BOUND>\"]:\n",
    "            break\n",
    "    x_tokens = [char_dict_reverse[indx] for indx in x_indxs]\n",
    "    x_string = \"\".join(x_tokens)\n",
    "    return(x_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_string = \"how many stereotypes does it take to light bulb change\"\n",
    "generator_topic = topic_modeler.transform([generator_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(model, layer, mask):\n",
    "    states = model.get_layer(layer)._states\n",
    "    states = [np.multiply(K.eval(state), mask) for state in states]\n",
    "    model.get_layer(layer).reset_states(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:21<00:00,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.5741\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>\"Haed brother guys giffed off tomeny... bit just new waitch the same behind, on a whosenseat walking in 2.\n",
      "\n",
      "carion day came, put poilely of my approptoleing the tophernt, thenry good/to boy.<BOUND>\n",
      "***** Epoch 2 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:51<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.3884\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A fay catch the trice take\n",
      "\n",
      "So the germanes! She says.\n",
      "\"I am in the cookh. As he asked the doctor.\" The priest, watches the store, and asks \"Oh mistcum, my way.\"\n",
      "The bartender gives a sign up and says \"No, answer.\" \n",
      "The man says \"Oh duck lady when it's confron, sit liveowi!\" As a man again: \"To want you with that it was there, it, so showed your word. I writped to here\" He's long you are..\" I help down the same and get his parpanet. So me, he snyed and peoss the last geod.  The cowboy flustorishes under her wine the body blowing rubbiwls using a beurind.\n",
      "      the whole on Marie, \"Two briate.  My chipf clubs her escar.  I here he poples on up that from house.\n",
      "The brulip tree was selow. So we bet forgot a cornor,\" and scratcher couldn't life his face for an's statious is, whateve know Ch  rictos - Viche is Hellvon!\n",
      "\"Mr. chamas?\" And ent given his wife's wraps a mednamy and made her spake, the next day he confused him for a refrige.\n",
      "Jobes but up had in the gates. This man smelled it, JIr\n",
      "***** Epoch 3 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:26<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.3077\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Have kack mething up?\n",
      "\n",
      "An more when sad<BOUND>\n",
      "***** Epoch 4 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [35:31<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.2588\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>I just want to cut the newly nulce for one idiat by her atom down the guys long with them more passenger\n",
      "\n",
      "is neck for bed that all.  But, going to put my board you've got a cigar. <BOUND>\n",
      "***** Epoch 5 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [35:16<00:00,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.2254\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Slabor and the young man other man walked back\n",
      "\n",
      "A three guy sitting in a female Bar: Hello. if you run to Irete for you? Nononight you must have a home controling. Willid see him your mother creatment!\n",
      "\n",
      "For behind him and knocked over a woman. He pulls over to the shelmen and looked at the sofa. \n",
      "\n",
      "He is hair, the ladies inches in the russy was bury over some came by with 19 sheriff down. This chanting the man's mother steps to talk to the course and says \n",
      "Beh, Tale. Joke, I really know how to drop her mother compassible.\n",
      "Tride burned at the front but the professor started the dog in the eye and the bus decides to go ahead that he has come to the sap! He responded, \"Wow! See what a Goodcon Trump are your sons of the prostitutes is dying for -the problem that had bar is worth\n",
      "ef. You should solve a clinsier and the kingdom, which Do fart of me hardw and behold him the laundres.\" No, the dad asks \"What do worry?\"\n",
      "The boy smiled and pulled it to this driveway. \"What go home service the gir\n",
      "***** Epoch 6 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:26<00:00,  8.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1999\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Deeo/YUANTIHROOEISJINLIYCL AN AND MIMEVESSSWERST 1 IRTOMANEGHO!!.!\n",
      "\n",
      "The game ready to his wife...<BOUND>\n",
      "***** Epoch 7 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:54<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1797\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What's the difficulahes my honor measures?\n",
      "\n",
      "A Rollsuc\n",
      "\n",
      "She has\n",
      "no one's emprisorp3red to do any plug.\n",
      "I was cuts it back. Ad he was decisiver.<BOUND>\n",
      "***** Epoch 8 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:04<00:00,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1614\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Condugin...\n",
      "\n",
      "Little Johnny's hand in the sheep. The snattoon has it in the arm, not staying at the sea! The businessman turns it to her. \n",
      "\n",
      "\"That would solve it again\" he reaches More Bigger, but the release matters asks \"Ma'am, I took the river rather on the shamvo! Morning? I buy permarked, and laughing hard away that it's about this chief mole.\"\n",
      "\n",
      "\"Wow! Is nervous going BAUVOASS?FO friend the Pil Rave all day as he lets our pundal operatorious.\" appliled fish and thinks on his profhy grase and tells her hes quiero-store, half-trick, more stuffs in them.\n",
      "\n",
      "\"Well, interviewing some technarps that three than when you've spend a new lighter, I mean with it apartment in the garden\n",
      "\n",
      "\"I'm 83 Ob!\"<BOUND>\n",
      "***** Epoch 9 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:59<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1468\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>I don't see what I want...\n",
      "\n",
      "r/Panece find a little old time<BOUND>\n",
      "***** Epoch 10 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:56<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1342\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What hippi no one is a tunnel?\n",
      "\n",
      "They're imaginable.<BOUND>\n",
      "***** Epoch 11 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:54<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1219\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Back of humoxatoun people.\n",
      "\n",
      "The green men went to their occupy of asphalusting. They didn't drink if rumour' after several swing, so they entered the earth. But and they had farmed for the table they stop asking, \"yeah I know some them!\"<BOUND>\n",
      "***** Epoch 12 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:55<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1105\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What did the rubber win a syrab drop when he'll be payment?\n",
      "\n",
      "Homerions <BOUND>\n",
      "***** Epoch 13 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:57<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.1035\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Humannace player\n",
      "\n",
      "A Jewish guy stares at the lobby and has to rush to see a month last night, braves on the phone, swealing right female forest to anal sees far shouting, \"Honey, Mommy, would I see Holiday Binch aroundeds?!\" Just shyliled up read at the base at a tand and thinks to himself, \"Say machine has to wall, and you have to put one every right help in perfects in the ass, but, no one much blades.\"\n",
      "<BOUND>\n",
      "***** Epoch 14 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:49<00:00,  8.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0928\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A blonde...\n",
      "\n",
      "A guy walks into a zoo red and asks for a play-9 apple tail. \n",
      "\n",
      "The woman asks his first hotel to her as well as a stony.  The very soldier asked \"That's pray at anticipation effort.\" \n",
      "\n",
      "The son asked for a while and walks up to her back. But the boy goes, \"Honey.  I'll lose a ride joke your wife's clothes.\"  The Chinese man said, \"Um\". No more glancely red.<BOUND>\n",
      "***** Epoch 15 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:55<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0856\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>I asked my ex-wife sailor if a large folded at a hat from Google.\n",
      "\n",
      "I thought he was having sex. I realized that at all of a solution \n",
      "of his head wanting them. I just just prepared a Malay Albano does her husband in it! I walked up to my ass, in terrible smile hot bah, . We could move apossom. I love you, we could shout it out, and squeezed unchaity - that type of until sign found them 'I usual shot in my pants!'<BOUND>\n",
      "***** Epoch 16 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:55<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0796\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What is the investigator\n",
      "\n",
      "Wha cat weighes up the name?<BOUND>\n",
      "***** Epoch 17 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:55<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0718\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Tell golfer this morning.\n",
      "\n",
      "Little Jimmy goes to keep the lizard who is greete two getting left at him home. \n",
      "\n",
      "The speech and one wives wolf without tea. The sweets of the cliff, out of the pent's routine, vanishings and sits at them.About, they cried Consure and *makes your wife embting in\"\n",
      "\n",
      "Brewing right down the street. The Dr  half a deepy sits in the store and yells.\n",
      "\n",
      "Now, the captain replies with a bat first is blonde bumps!\n",
      "\n",
      "Hell: That must have been a tattoo.    Army. Getting loud.<BOUND>\n",
      "***** Epoch 18 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:55<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0650\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>How do you make a hen eat girl from take of apply?\n",
      "\n",
      "It doesn't hear it until I prefer.<BOUND>\n",
      "***** Epoch 19 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:59<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0627\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>My daughter were twipned from a diminut of 200\n",
      "\n",
      "I was behind me that bened on a fence. Chip : Vairon\"\n",
      "\n",
      "3. Women one day, he slipped off the plane and said, \"I think it's a bad of spiritual's only programmers game.\"\n",
      "\n",
      "10. Theyre emotived titlence\n",
      "\n",
      "Literallyavencing:\n",
      "\n",
      "Jewish kids jumps onto a bus...\n",
      "\n",
      "\"I think my West Symcony Polish is:\"\n",
      "\n",
      "Witn:\n",
      "\"Hey Bill? Why will have you get an inflighty mind, but nothing willing to?\"\n",
      "\n",
      "Parkins: **FISSIHS most but what if I do were you?*(Did the government do with his house out\n",
      "today usually he managed to bite him?\n",
      "\n",
      "On Mother Conversance has licking it away.\n",
      "\n",
      "2.)  Eventually shut up from the maternic customur<BOUND>\n",
      "***** Epoch 20 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:52<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0542\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>How choose your wifes in line?\n",
      "\n",
      "Me how can you go shirtyripher?\n",
      "\n",
      "Kick it all day.<BOUND>\n",
      "***** Epoch 21 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:00<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0504\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Recettumbir Gally...\n",
      "\n",
      "The plan talked into a drug store. A Horpable when they came across a serious people. Hitler was delighted for his fantes of 9/11 north. He knew which he cheated over her which since that he bet himself to the bathroom to have the party on his father.\n",
      "\n",
      "\"In the doctors shifting dog!\"  \n",
      "\n",
      "As he just stumbled down, the professor asked, \"How do you think I break from?\"\n",
      "\"Well No, he was dead, and the Malaysian was to-girl with my inebror over her mouth. I couldn't believe it yet in ceremony and then friend accounts hauling for an ice cream hang and because the dad scared your undile bar on the light\" she explained that the birdcone became the last button.\n",
      " \n",
      "\n",
      "\"DEDPE THIN!? It's terrible to over! How do you detective a sledge foot?\" The girl with himself said, \"You idiot!\"\n",
      "The bartender tells him: \"I want you to ten. I live alone, and all helpped to this a priest.\"   \n",
      "Boy said, \"Shut it any prayers, because the specimens are junk\"  \n",
      "Oh, you have a very long time I have a \n",
      "***** Epoch 22 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:00<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0470\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Dark in a date..\n",
      "\n",
      "A teacher says \"Peter!\" The first one says \"YES DO Deplt dye you're 34 years!\" The clown looks them and then crawls onto the coffee table. The grandpa turns on the emerging to the Father: \"Because of you really have your rulbing law's tequila.\"\n",
      "Cop: \"just sitting down.\"\n",
      "The owner offers her and says: \"I'll turn into a \"Armon\" \n",
      "They hands the Cheerio they make love down on the water and the pilots manager have one lifena, after who predicts him\"\n",
      "Man: \"That's quite a minute, nor as something like shit, we'll just keep the fuck in a transdet, the daughter\n",
      "said that the third cool thought he'd keep the little taken?\"  \n",
      "God says how could she know what the princiter is like about?\"<BOUND>\n",
      "***** Epoch 23 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:57<00:00,  8.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0406\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Whats the has golfing and coordions so matter?\n",
      "\n",
      "Cordurace.\n",
      "<BOUND>\n",
      "***** Epoch 24 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:03<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0365\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Husband don't shrike\n",
      "\n",
      "Little Johnny walks into a bank in his own socket and says to the woman, \"What come speeding? I was shop with this posture.\" He talks to god about how she is alive. The boy then pulls out your hat, put on her hair and starts moving forward to see the black Indians be outta football one program. So they decide to meet moven the house with the lake on water of being<BOUND>\n",
      "***** Epoch 25 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:07<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0359\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>You know what they drop that behind in a Dutcitial Asian\n",
      "\n",
      "You get two.<BOUND>\n",
      "***** Epoch 26 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:12<00:00,  8.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0292\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>I got in to a woman who proceeded to roal, but I have been to Price with my vagina.\n",
      "\n",
      "I never forget my intends in the dark book but I've never heard of interest policemen. I'm sorry. <BOUND>\n",
      "***** Epoch 27 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:23<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0267\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>My favorughembers are standing in the original accident. Now what you think there is an electricity built in your house.\n",
      "\n",
      "They both sting<BOUND>\n",
      "***** Epoch 28 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:40<00:00,  9.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0252\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A too woman's snake some is late to a difference as having taken.\n",
      "\n",
      "His father blew up to visible so he asks, \"If so fill her son do you drink a house?\"\n",
      "\n",
      "The father says, \"sometimes the chicken makes me in with mine<BOUND>\n",
      "***** Epoch 29 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:59<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0200\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>The were a lie to debate wedding\n",
      "\n",
      "Once there was half weather at the FUR letter - If you come with you a single kind of ears. Thought there was a most trap, unusual lined by girls and have sex with it. \n",
      "\n",
      "But Barack Cuban comes down and talk downstairs and it felt that everyone causes German and Kim. Obtive screamed twice by the second guy named His Na.<BOUND>\n",
      "***** Epoch 30 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:03<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0165\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>An old couple was waiting for helicate the little boy assistant was a disgrun...\n",
      "\n",
      "Two Irishmen went to something back and saw their waiter.\n",
      "\n",
      "The first daughter had any Sunday, he began to him to pick up so, and run towards the beer, then while he's in the eye doc, he gets the small order of that sexual symphony in on his arrival. Years ago , his roommate sharps the only smart time. Then he stands in, and Caddy Kature bottle of wine, really. He's fine dayline to come from, but helloogh. So the two pickup tucks up bites in his lage on. But when Bill snumbs you in wood, I bet it a ticket in the rival. Good and shit.<BOUND>\n",
      "***** Epoch 31 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:23<00:00,  8.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0174\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>There was on a fluming stick.\n",
      "\n",
      "On Pence Same member's favorite people who sneak them in one of their type rooms to the court.\n",
      "\n",
      "2 whores had enough within the wine briefcharist.\n",
      "\n",
      "Furken to a white girl who wanted to deal with him.\n",
      "\n",
      "\"Did you jump off?\" asked the driver.\n",
      "\n",
      "\"I would still come into Washington,\" he said. \"I want you a mood face!\"<BOUND>\n",
      "***** Epoch 32 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:30<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0108\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Why did the prostitute from Please and make it to New Zealand cum that are fat?\n",
      "\n",
      "Because why only their finger know it was!<BOUND>\n",
      "***** Epoch 33 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [35:33<00:00,  8.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0102\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What do you call a veganaim in bed?\n",
      "\n",
      "An airport in Wrights!<BOUND>\n",
      "***** Epoch 34 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:43<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0089\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A man walks into a bar and comes into the train. \"We 's are going to kill it,\" and grinned \"I don't always be gentle.\"\n",
      "\n",
      "\"What, last night I didn't then? My boy asked me th \"she came home to me* I meant today when I saw the other two M Shallengy. He's pisses off but he'd be so drunk good!\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Bubble behind the car].<BOUND>\n",
      "***** Epoch 35 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:05<00:00,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0032\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Steve T;0. Chris Bowlee Should Carol Arrive Anator...\n",
      "\n",
      "A marchist ever drives home we met, got an illegable professional drawing, cooled strong. Zew guy never couldn't find him...\n",
      "then \n",
      "The fifth car broke in more rites, and she said that son of a bitch just opened his face as hard as he wondering what was most lifeless region for me. So John, on the brochard look back and slept them back into the woods, looking to recreate friends. No...<BOUND>\n",
      "***** Epoch 36 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:03<00:00,  8.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0023\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Some man think its your girlfriend isn't \"many\" she's going to ask why the other completes is to offend my ears about the wrong's sister.\n",
      "\n",
      "I said, \"My wife didn't work for my balls is here.\"<BOUND>\n",
      "***** Epoch 37 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:02<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0037\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A wur Military Officer decides to donate sniffed lettuce must care.\n",
      "\n",
      "So this geroume has a good time. Using nervous country is general about her right he moves to the family's dapes that is exotic, Tom Schitt appears to retrieve the spots to satisfy her book and Sister. TO her 20as, Colin, with private jobs, love means next to me to funch to our course. She drops her mouth, I climbed out of the closet and rubbed all of the three tables in her husbands loming over and said \"What's wrong with me\"<BOUND>\n",
      "***** Epoch 38 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:59<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.9974\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Happy The Panther Beight was being vending was getting beaten moments.\n",
      "\n",
      "His friends smile at the shaped arm and threw him. Is coming back to look for me it has a drink.<BOUND>\n",
      "***** Epoch 39 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:06<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.9979\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Some gorilla lingered porn?\n",
      "\n",
      "MK. folks.<BOUND>\n",
      "***** Epoch 40 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▉                                                                                | 6/250 [00:51<35:06,  8.63s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e31c06a87aad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMONITOR_FREQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mchar_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"char_indx_input\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mchar_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"topic_input\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopic_input\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#now masking bit...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTOTAL_DEPTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now a loop\n",
    "epoch = 0\n",
    "training_model.reset_states()\n",
    "#need initial ys...\n",
    "while True:\n",
    "    epoch+=1\n",
    "    print(\"***** Epoch {} *****\".format(epoch)) \n",
    "    loss = np.zeros(MONITOR_FREQ,dtype=np.float32)\n",
    "    for i in tqdm(range(MONITOR_FREQ)):\n",
    "        char_input, y, topic_input, state_mask = next(gen_seq)\n",
    "        loss[i] = training_model.train_on_batch(x={\"char_indx_input\":char_input, \"topic_input\":topic_input}, y=y)\n",
    "        #now masking bit...\n",
    "        for i in range(TOTAL_DEPTH):\n",
    "            reset_states(training_model, \"rnn\"+str(i), state_mask)\n",
    "    #checkpointer\n",
    "    training_model.save(\"models/\"+MODEL_NAME)\n",
    "    print(\"Average loss of {:.4f}\".format(np.mean(loss)))\n",
    "    print(\"***** EXAMPLE OUTPUT*****\")\n",
    "    predict_model.set_weights(training_model.get_weights())\n",
    "    joke = generate_joke(predict_model, generator_topic, char_dict, max_len=1000)\n",
    "    print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "wghts = predict_model.get_layer(\"rnn2\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 512)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wghts[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 512)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wghts[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wghts[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16500622,  0.07672426, -0.12786634, -0.00612003,  0.13232455,\n",
       "       -0.12390276, -0.07230407, -0.15616518, -0.06531354, -0.09285146,\n",
       "        0.14022237, -0.07699914,  0.70327419, -0.07669064,  0.15126373,\n",
       "        0.0199868 , -0.14625588, -0.19004793, -0.27385962, -0.00417563,\n",
       "       -0.07728644, -0.0612554 ,  0.04068965, -0.06528439,  0.04827083,\n",
       "        0.03167893, -0.14356853,  0.12293271, -0.09711115,  0.03461432,\n",
       "       -0.04996607, -0.1054599 ], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wghts[2][64:96]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05873594, -0.20834757, -0.19437824, -0.08044638, -0.13555704,\n",
       "        0.0750309 , -0.016366  , -0.04769966, -0.14590505,  0.1670956 ,\n",
       "       -0.01992786, -0.0447577 , -0.18429899, -0.02186309, -0.03105482,\n",
       "        0.04352831,  0.06178947,  0.01678973, -0.03070449, -0.01133532,\n",
       "       -0.08905493, -0.00231288,  0.11056606, -0.09005753, -0.26728538,\n",
       "        0.02797053, -0.08320679, -0.08874695, -0.14318527, -0.20703405,\n",
       "        0.0816564 ,  0.20222224], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wghts[2][0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
