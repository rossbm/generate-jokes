{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Romance only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from math import exp\n",
    "import pickle\n",
    "from importlib import reload\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import Sequence\n",
    "from keras import Model\n",
    "from keras.layers import Dense, Input, Masking, BatchNormalization, Layer, Embedding\n",
    "from keras.layers import LSTM, Reshape, TimeDistributed, Concatenate, Multiply, RepeatVector\n",
    "from keras.optimizers import Nadam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.path.join(os.getcwd(), os.pardir)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import helpers\n",
    "helpers = reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CHARS_SEQS_PATH = \"data/joke_char_sequences_Jan20.h5\"\n",
    "TOPICS_PATH = \"data/joke_topics.pkl\"\n",
    "TOPIC_MODELER_PATH = \"data/jokes_topic_modeler.pkl\"\n",
    "CHAR_DICT_PATH = \"data/char_dict_Jan20.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=512\n",
    "#this is nubmer of 128 layers + 1 (there is layws at least one 127 (unit layers))\n",
    "\n",
    "#i wonder if lstm is necasry of gru woruld work\n",
    "MIDDLE_DEPTH=3\n",
    "SEQ_LENGTH = 300\n",
    "RELOAD = None\n",
    "MODEL_NAME = \"rnn_jokes_topics_Jan25.hdf5\"\n",
    "#BASE_CELL_SIZE=64\n",
    "#should change to maybe max seq length...\n",
    "#for varios monitoring applications\n",
    "MONITOR_FREQ=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#easier to define here\n",
    "TOTAL_DEPTH = MIDDLE_DEPTH + 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5f = h5py.File(CHARS_SEQS_PATH, \"r\")\n",
    "seqs = h5f[\"seqs\"][:]\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109095,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load char dict\n",
    "pickle_in = open(CHAR_DICT_PATH,\"rb\")\n",
    "char_dict = pickle.load(pickle_in)\n",
    "pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "num_chars=len(char_dict)\n",
    "print(num_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load encoder\n",
    "topic_modeler = joblib.load(TOPIC_MODELER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load topics\n",
    "topics = joblib.load(TOPICS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "topic_size = topics.shape[1]\n",
    "print(topic_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharGenSequence(Sequence):\n",
    "    def __init__(self, seqs, char_dict, topics, batch_size=500, seq_length=50, initial_idxs=None):\n",
    "        self.seqs = seqs\n",
    "        self.char_dict = char_dict\n",
    "        #need to know how big input to neural net (length of sequnece)\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        #the  random permtuion returns a randomly sorted rangs\n",
    "        self.seq_idxs = np.random.permutation(len(seqs)).tolist()\n",
    "        #now intitilize first batch\n",
    "        #these are the indexes of seq_list that are used for the batch.\n",
    "        #queu will help, can pop from left\n",
    "        self.available_idxs = deque(self.seq_idxs.pop() for _ in range(2))\n",
    "        self.batch_idxs = [self.seq_idxs.pop() for _ in range(self.batch_size)]\n",
    "        \n",
    "        #ALWAYS START AT BEGINNING...\n",
    "        self.seq_pos = [0 for seq in self.batch_idxs]\n",
    "        \n",
    "        #be such athat batch_size*prob/(self.batch_size + len(self.available_idxs) = 1/25?\n",
    "        self.prob_multi = 10\n",
    "        self.chance_for_new = (self.batch_size)/(self.prob_multi * (self.batch_size+len(self.available_idxs)))\n",
    "       \n",
    "        #now topics\n",
    "        self.topics = topics\n",
    "        topic_dim = self.topics.shape[1]\n",
    "        \n",
    "        self.batch_topics = np.zeros((self.batch_size, topic_dim), dtype=np.float)\n",
    "        \n",
    "        #now fill\n",
    "        for ix, batch_idx in enumerate(self.batch_idxs):\n",
    "            self.batch_topics[ix, :] = self.topics[ix, :]\n",
    "        \n",
    "    def __next__(self):\n",
    "        #make masks\n",
    "        #used to determine if will use reset state or not...\n",
    "        #will rely on brtaod casting to gie ii th eproer shape\n",
    "        state_mask = np.ones((self.batch_size, 1), dtype=np.float32)\n",
    "        #make x, the input a numpy array of zeros (initilaly)\n",
    "        #nowing providing just indexes, since\n",
    "        x = np.zeros((self.batch_size, self.seq_length, len(self.char_dict)), dtype=np.float)\n",
    "        \n",
    "        #will use sparse categorical\n",
    "        y = np.zeros((self.batch_size, self.seq_length, 1), dtype=np.int32)\n",
    "        \n",
    "        #chance to introduce a new text into rotation decreases as the number of texts in rotation icreases\n",
    "        self.chance_for_new = (self.batch_size)/(self.prob_multi * (self.batch_size+len(self.available_idxs)))\n",
    "        \n",
    "        #LOOP OVER BATCH\n",
    "        #seq_idx is the index of the sequnce within seq_list\n",
    "        #while batch_idx is the index of the sequence within the batch        \n",
    "        for batch_idx, seq_idx in enumerate(self.batch_idxs):\n",
    "            #work fowards...\n",
    "            #GO UP TO LENGTH OF OUTPUTS...\n",
    "            #check if this will be last batch for this input seq\n",
    "\n",
    "            for pos_idx in range(self.seq_length):\n",
    "                #self.seq_pos is start of sequence\n",
    "                input_pos_idx =  self.seq_pos[batch_idx]+pos_idx\n",
    "                #OUTPUTS ALWAYS ONE AHEAD OF INPUTS\n",
    "                output_pos_idx = input_pos_idx + 1\n",
    "                #if desired index does not exit, leave blank....\n",
    "                try:\n",
    "                    x[batch_idx, pos_idx, self.seqs[seq_idx][input_pos_idx]] = 1.\n",
    "                except IndexError:\n",
    "                    #leave at default of 0 (padding value)\n",
    "                    pass\n",
    "                try:\n",
    "                    y[batch_idx, pos_idx, 0] = self.seqs[seq_idx][output_pos_idx]\n",
    "                except IndexError:\n",
    "                    #will be masked anyways?\n",
    "                    y[batch_idx, pos_idx, 0] = self.char_dict[\"<BOUND>\"]\n",
    "        \n",
    "\n",
    "            #DO SPECIAL STUFF IF length of sequence is less than than what was desired...\n",
    "            if len(self.seqs[seq_idx]) <= (self.seq_length + self.seq_pos[batch_idx]):\n",
    "                #first ass toavaialbe\n",
    "                self.available_idxs.append(self.batch_idxs[batch_idx])\n",
    "                \n",
    "                #update self.seq_indxs to get a new seq\n",
    "                if (random.random() <= self.chance_for_new) and (len(self.seq_idxs) >0):\n",
    "                    self.batch_idxs[batch_idx] = self.seq_idxs.pop()\n",
    "                else:\n",
    "                    self.batch_idxs[batch_idx] = self.available_idxs.popleft()\n",
    "                    \n",
    "                #set star pos back to 0\n",
    "                self.seq_pos[batch_idx] = 0\n",
    "\n",
    "                #get new word_indxs and wghts\n",
    "                self.batch_topics[batch_idx, :] = self.topics[self.batch_idxs[batch_idx], :]\n",
    "                \n",
    "                #make masks = 0 to reset state\n",
    "                #could probaly do this outside of the generator...\n",
    "                state_mask[batch_idx,0] = 0.0\n",
    "            else:\n",
    "                #increment position by seq_length\n",
    "                #want last output character to be the first input character...\n",
    "                self.seq_pos[batch_idx]=self.seq_pos[batch_idx]+ self.seq_length\n",
    "        return(x, y, self.batch_topics, state_mask)\n",
    "    def __iter__(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "gen_seq =  CharGenSequence(seqs, char_dict=char_dict, topics=topics, seq_length=3, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ACTUAL\n",
    "gen_seq =  CharGenSequence(seqs, char_dict=char_dict, topics=topics, seq_length=SEQ_LENGTH, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from helpers import  sparse_softmax_cross_entropy_with_logits\n",
    "from helpers import WghtdAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this layer makes \n",
    "class Standardize(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Standardize, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "    def call(self, inputs, mask = None):\n",
    "        #first, mean of 0\n",
    "        inputs = inputs - K.mean(inputs, axis=-1, keepdims=True)\n",
    "        #now, want to induce a variacne of 1\n",
    "        inputs = inputs / (K.sqrt(K.mean(K.square(inputs), axis=-1, keepdims=True)) + K.epsilon())\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(batch_size, input_length, num_chars, rnn_depth=1, topic_size=32):\n",
    "    #character sequences\n",
    "    character_input = Input(batch_shape=(batch_size,input_length, num_chars), dtype='float', name='char_indx_input')\n",
    "    masked = Masking(name=\"mask\")(character_input)\n",
    "    #topic input\n",
    "    topic_input = Input(batch_shape=(batch_size, topic_size), dtype='float', name='topic_input')\n",
    "    topic = Standardize()(topic_input)\n",
    "    topic_repeated = RepeatVector(input_length, name=\"repeat_topic\")(topic)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #first, to get to 32\n",
    "    rnn =  LSTM(units=32,return_sequences=True, stateful=True, name=\"rnn0\")(masked)\n",
    "    rnn = sequences = BatchNormalization(name=\"normalize0\")(rnn)\n",
    "    #now 64\n",
    "    rnn =  LSTM(units=64,return_sequences=True, stateful=True, name=\"rnn1\")(rnn)\n",
    "    #now concatenate topic..\n",
    "    sequences = Concatenate(name=\"concatenate\")([rnn, topic_repeated])\n",
    "    sequences = BatchNormalization(name=\"normalize1\")(sequences)\n",
    "    \n",
    "    for i in range(rnn_depth):\n",
    "        rnn =  LSTM(units=128,return_sequences=True, stateful=True, name=\"rnn\"+str(i+2))(sequences)\n",
    "        sequences = BatchNormalization(name=\"normalize\"+str(i+2))(rnn)\n",
    "\n",
    "    #now 256 *maybe 512?\n",
    "    #should have argument...\n",
    "    rnn =  LSTM(units=256,return_sequences=True, stateful=True, name=\"rnn\"+str(rnn_depth+2))(sequences)\n",
    "    sequences = BatchNormalization(name=\"normalize\"+str(rnn_depth+2))(rnn)\n",
    "    rnn =  LSTM(units=512,return_sequences=True, stateful=True, name=\"rnn\"+str(rnn_depth+3))(sequences)\n",
    "        \n",
    "    preds = TimeDistributed(Dense(num_chars), name=\"logits\")(rnn)\n",
    "    model = Model(inputs=[character_input, topic_input], outputs=preds)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_indx_input (InputLayer)    (512, 300, 98)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask (Masking)                  (512, 300, 98)       0           char_indx_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "rnn0 (LSTM)                     (512, 300, 32)       16768       mask[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "topic_input (InputLayer)        (512, 32)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalize0 (BatchNormalization) (512, 300, 32)       128         rnn0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "standardize_1 (Standardize)     (512, 32)            0           topic_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn1 (LSTM)                     (512, 300, 64)       24832       normalize0[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_topic (RepeatVector)     (512, 300, 32)       0           standardize_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (512, 300, 96)       0           rnn1[0][0]                       \n",
      "                                                                 repeat_topic[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "normalize1 (BatchNormalization) (512, 300, 96)       384         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "rnn2 (LSTM)                     (512, 300, 128)      115200      normalize1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize2 (BatchNormalization) (512, 300, 128)      512         rnn2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn3 (LSTM)                     (512, 300, 128)      131584      normalize2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize3 (BatchNormalization) (512, 300, 128)      512         rnn3[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn4 (LSTM)                     (512, 300, 128)      131584      normalize3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize4 (BatchNormalization) (512, 300, 128)      512         rnn4[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn5 (LSTM)                     (512, 300, 256)      394240      normalize4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normalize5 (BatchNormalization) (512, 300, 256)      1024        rnn5[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "rnn6 (LSTM)                     (512, 300, 512)      1574912     normalize5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "logits (TimeDistributed)        (512, 300, 98)       50274       rnn6[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 2,442,466\n",
      "Trainable params: 2,440,930\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "training_model = create_model(batch_size=BATCH_SIZE, input_length=SEQ_LENGTH, num_chars=num_chars,\n",
    "                              rnn_depth=MIDDLE_DEPTH, topic_size=topic_size)\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RELOAD is not None:\n",
    "    #this might not work since last layer is a different size\n",
    "    #might have to load manually (for first...)\n",
    "    training_model.load_weights(\"models/\"+RELOAD, by_name=True)\n",
    "    training_model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_model.compile(loss=sparse_softmax_cross_entropy_with_logits, optimizer=Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make prediction model\n",
    "#batch size of one, and only on time step\n",
    "predict_model = create_model(batch_size=1, input_length=1, num_chars=num_chars,\n",
    "                             rnn_depth=MIDDLE_DEPTH, topic_size=topic_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since this is version one, need to freeze first rnnlayer (so dont lose beautiful weihts...)\n",
    "#training_model.get_layer(name=\"rnn0\").trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SHOULD ADD SOME SORT OF BIAS AGAINST END CHARACTER....\n",
    "def sample(preds, end_indx, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    #is logged proability\n",
    "    #so exp(log(prob) / temperature) is smaller when temperature is higer\n",
    "    #however derivative respect to temp: -log(prob) /temperature^2\n",
    "    #-log(prob) is bigger when prob is smaller\n",
    "    #so result is that lower temp makes smaller probs go to 0 faster\n",
    "    preds = preds / temperature \n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEED TO PROVIDE A \"topic\"\n",
    "def generate_joke(model, topic, char_dict, max_len=1000, temperature=1.0):\n",
    "    model.reset_states()\n",
    "    #intitial is just a batch size of 1, and timstep of one\n",
    "    #now, don<t need thrid dimensinm\n",
    "    x_input = np.zeros((1,1, len(char_dict)), dtype =np.float32)\n",
    "    \n",
    "    #make a reverse dic\n",
    "    #might want to make into a method\n",
    "    #not certain if that is possible\n",
    "    #substract one, since preciotns are different\n",
    "    char_dict_reverse = {value:key for key, value in char_dict.items()}\n",
    "    #make first indexes equal to 1 (start)\n",
    "    x_input[0,0, char_dict[\"<BOUND>\"]] = 1.0\n",
    "    #x_indxs is used to output, ant htius genrate jokes\n",
    "    x_indxs = [char_dict[\"<BOUND>\"]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        #want a decreasing temperature\n",
    "        temperature= 0.5*exp(i*-0.1)\n",
    "        #want only first...\n",
    "        preds = model.predict_on_batch(x={\"char_indx_input\":x_input, \"topic_input\":topic})[0,0]\n",
    "        next_index = sample(preds, end_indx=char_dict[\"<BOUND>\"], temperature=1)\n",
    "        #only need to update first index, since stateful...\n",
    "        #make x_input again\n",
    "        x_input = np.zeros((1,1, len(char_dict)), dtype =np.float32)\n",
    "        x_input[0,0,next_index] = 1.0\n",
    "        #now append to list that is used for text genration...\n",
    "        x_indxs.append(next_index)\n",
    "        if next_index == char_dict[\"<BOUND>\"]:\n",
    "            break\n",
    "    x_tokens = [char_dict_reverse[indx] for indx in x_indxs]\n",
    "    x_string = \"\".join(x_tokens)\n",
    "    return(x_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_string = \"blonde redhead\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator_topic = topic_modeler.transform([generator_string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joke = generate_joke(predict_model, generator_topic, char_dict, max_len=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOUND>y/!.:/%'E<BOUND>\n"
     ]
    }
   ],
   "source": [
    "print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(model, layer, mask):\n",
    "    states = model.get_layer(layer)._states\n",
    "    states = [np.multiply(K.eval(state), mask) for state in states]\n",
    "    model.get_layer(layer).reset_states(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch 1 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:02<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 2.4930\n",
      "Iterating over 3003 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>HTee o e pe?y ea fectio .e aicwsie i  fok\n",
      "!e tn! 'a ao o iaaiaaeas T e a ,i'ea f a,'a. eala   ai,iwaeis a   w\n",
      " e\n",
      "v a   ii,aaiaaao,eow aeoi  it.eaa ia ?ed  adr a!y. eiio . afeisoioi. 'veiy.a aif,a! vi aedeo  ia iem aisay. ye ..s eifa?aats.  iajaer\n",
      "e e.. as\n",
      "oae e i aa,a f\n",
      "  ae.ee.mtaiixao.ae iiiiue eua o\n",
      "n'hiteoi,o.? . 'et. aetwa .a. .otaod ieke. t, ir aautae..a\n",
      ".  sa i aiea,amaew..uarf\n",
      "aoa.ioa tia!a  ar aat\n",
      "N\"re.o eet eata aeieay va,via e?,aibmay.is aa , iiuae assu..! iaul.?\n",
      " a\n",
      "s. esat iooinale.as\n",
      "al fa sysiye. r ,oeatfaye. ioe.aade aa  oat.\n",
      "\n",
      "rnLeVai aa\n",
      "y\n",
      "ao.siaiaiaeiel, aio ? o.oaa  acei sa. a aifiooa atso  . afe atiy?ae .ysi .a aEi  lt.eee a \n",
      ". mem e,y ye aaa,t tai.oe.sl oao, .?..ndn  tcabr  uai ti y.ailvaaela.uare ao\n",
      ".oo\"saeen. \n",
      "a . ele'aee o.o eo'ya o. yr  n!i eo.s.hn  e.o a.sy.oo.oo ?.. ose\n",
      "aa oi afa eaite.eaio t.ta a ia\n",
      "m au  w; e  iitesiayci. o. e*aoo ee   alo abe ooae g.o o awea  .e\n",
      ". ebim pA  fa  e ireietavai a.ar eees man,a.\n",
      "sie.e.sa'e sa 'medi t'lf aaa.aaei eanfa\n",
      "\"!fsoa sjfat\n",
      "***** Epoch 2 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:42<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.3255\n",
      "Iterating over 4178 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Wane eet beet gutter Rave\n",
      " teag an .adabe\n",
      "\n",
      " butter, Muttere\n",
      "\n",
      "Nuvon\n",
      " toeve. eepes\n",
      "<BOUND>\n",
      "***** Epoch 3 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:46<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 1.0859\n",
      "Iterating over 5077 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A mainman gets suiting a blond\n",
      "\n",
      "An old man gets unfortunate small pays and his seat on inside not get his eighters, bloust window with a smile of divine and responsed, \"DADINHEGHTEOL TONETTWONE!\"\n",
      "\n",
      "Cheese lifted the man and told him,\n",
      "\n",
      "The mom's the animals she says, \"Sir, I have Jest wise.\"\n",
      "\n",
      "She propped it in the house landrold for herself and said:\n",
      "\"I'm still a brother-gradea.\"\n",
      "\n",
      "The man then uponeds a good grand, and punches her plaster and her listens unounteens, \n",
      "\n",
      "after a drink, and the bigest gets kick.\n",
      "\n",
      "The mother knocking his towurse and still comend. \"I have a dancer the son, you have a whitzly, I kept hired green times I go he removed shreez, but I was right.\"\n",
      "\n",
      "Her then whispers got some wing and die.\n",
      "\n",
      "\"No, he's just an opposed because there were my ass I've been goin? Last 3 times when your mom symiles are only hima*\"\n",
      "\n",
      "Cugar climbingly, pauses the young up and goes to the people chickens\n",
      "\n",
      "The third said, the bartender  ureus my butt towards \n",
      "\n",
      "They praging to play the neighbor t\n",
      "***** Epoch 4 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:42<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.9659\n",
      "Iterating over 5833 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Why was God cress\n",
      "\n",
      "Because they realize I'm not The 7 bodde.<BOUND>\n",
      "***** Epoch 5 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:44<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8867\n",
      "Iterating over 6502 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>How do you make food so about?\n",
      "\n",
      "Because they're a strong the resist.<BOUND>\n",
      "***** Epoch 6 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:53<00:00,  8.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8295\n",
      "Iterating over 7097 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Have you ever lingaring...\n",
      "\n",
      "...but I'll empty this at the Home<BOUND>\n",
      "***** Epoch 7 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:47<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7851\n",
      "Iterating over 7616 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Ryodrile are like told once.\n",
      "\n",
      "A guy works in the back young man how his particians died.\n",
      "The Big going joke in a make, getting into `igt completely raps in gaing in the middle of the size deer. After sings, one points to the room comes down down below. He says to his mom, \"Today is my ten years I believe I was in there with!\" The driver replied: \"Don't be the only rights!\"<BOUND>\n",
      "***** Epoch 8 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:47<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7567\n",
      "Iterating over 8113 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A farmer whale break factory just goes home for living instead of his wife...\n",
      "\n",
      "\"I was gonna be 11 children! \"God helf also ever happens over the little hole.\" The lioness man back into his arms dials in. The bartender asks. \"We were gonna tell ya that your mans can get the wall he oweer the quali ouse will be in the counter.\"\n",
      "\n",
      "Only Johnny says, \"No, i better see you screamin\", he says it out to swallow. The officer looks up at the bartender with a meetic, a foot clean. The second man appears and asks instructor \"leadmin\" so he snucoms upstairs, the judge responded with \"the bar takes one breasts equipment the tits once, and he can't hold on. 'I'd make a car accident and leave!\" <BOUND>\n",
      "***** Epoch 9 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:38<00:00,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7357\n",
      "Iterating over 8569 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>So appresented to always got turned on their front door\n",
      "\n",
      "and thousands of life, wondering's thermome. \"How high?\" Rried: \"No. I've been die that Holmes with you!\" \n",
      "<BOUND>\n",
      "***** Epoch 10 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:43<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7237\n",
      "Iterating over 9024 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Two guys walk up to sky\n",
      "\n",
      "\n",
      "A little boy all left his girlfriend then was sitting at the Harry, show his wife around the kitchen windwing again. \"Please help me! We could sleep heaven, and found Yat many will hear that!\" he says:\n",
      "\n",
      "Confused, Johns and Little Europe with a white power. He proceeds to reveal his laptop parties and hands it to his wife.\n",
      "The officer says to him what happened!\n",
      "After about 20 minutes he had a dream of the way though the remainece started to wrip himself as the stripper.\n",
      "\n",
      "\"Do you like to pay the prize of your father?\"\n",
      "\n",
      "\"Well,\" the professor smiled, and he yards his greet up there and the car started stining.\n",
      "\n",
      "All the police approaches the cap. With the confessional.\n",
      "\n",
      "\"Why's thatcho?, Ferrari?\"\n",
      "\n",
      "\"It's no bigger during the privater side now, but it's just the 30 students when NFTETHE  And IK IT HOANER OMEWK TITER!\" Once said, \"The answers are ready for college, right labatter who tells something with anticipation.\"<BOUND>\n",
      "***** Epoch 11 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:45<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7276\n",
      "Iterating over 9457 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>black agents on the moon with a 100 does the same watcher...\n",
      "\n",
      "Are the year went gold cousies is called the floor suppers on ear the black further. \n",
      "\n",
      "But never would last plane<BOUND>\n",
      "***** Epoch 12 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:53<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7219\n",
      "Iterating over 9848 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What does a woman get first chopping tomor?\n",
      "\n",
      "A guide.<BOUND>\n",
      "***** Epoch 13 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:47<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7189\n",
      "Iterating over 10266 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What was staming in techns?\n",
      "\n",
      "A man beats his little available.<BOUND>\n",
      "***** Epoch 14 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:42<00:00,  8.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7217\n",
      "Iterating over 10657 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A drunk skyas and wall were free...\n",
      "\n",
      " handing out the window and finds a bag of meeting jarrowm. \n",
      "So she fell down and drays and tell each others crying a smile tomates. He tells the lawyer's wishes, \"Ms, BIMG nurst is cure and the 3 bar - I got it working on me,\" not all of the kitchen. Oghthouse broke, this guy is rushling good and ends up within a four-hotove-remasmakes via viol sendive. They meet an already began to rad out that poor unappen, they took him they fell asleep was ecstatic. \n",
      "\n",
      "  The audien girl could deer hear straight from this room for the custards instant.    Eaxhoned the dog. \n",
      " \n",
      "Since morning, long and larged his test-form of some Idiot happening sveter and pulled that one of them did not listen genie. Chris, she said, \"Logg`ds, not worry, then, you're going to get marry - 2 I'm 5811,\" she said.  \"No\n",
      "\" and She has them right behind her. \n",
      "Black changed, and for all.\n",
      "A newlywed couple more, after minutes, she starts drinking away his round there. After babies are seni\n",
      "***** Epoch 15 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:46<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7244\n",
      "Iterating over 11016 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A man walks into a bar\n",
      "\n",
      "and asks the magic word. \"DY that I don't have candy for the cheese,\" the Italian man, assezent, \"And I'll take my life to walk, and threw him away from the tickets.\"\n",
      "The bartender gets out of the left. \"Tummy, Ill love you!\"\n",
      "\n",
      "The suprofessed, \"he was the church was all over there weak.\"<BOUND>\n",
      "***** Epoch 16 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [37:01<00:00,  8.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7287\n",
      "Iterating over 11356 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Why did the Snowman tell the country that dies grows like?\n",
      "\n",
      "He didn't they want to be a pitchfork.<BOUND>\n",
      "***** Epoch 17 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:52<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7368\n",
      "Iterating over 11692 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What's a soda...\n",
      "\n",
      "A pastor, along as well a computer all instinct; the Australian says confused in check the plain \"Nurse chicks hack stumped around.\"<BOUND>\n",
      "***** Epoch 18 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:52<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7391\n",
      "Iterating over 12013 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>So this guy is selling firing...\n",
      "\n",
      "When a straw in experience with a bottle more amazing, the monks means get onto the street and yells \"Got this here was!\"<BOUND>\n",
      "***** Epoch 19 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:46<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7424\n",
      "Iterating over 12294 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What do you call more when we had a sentence too dafried?\n",
      "\n",
      "May men't coos.<BOUND>\n",
      "***** Epoch 20 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:47<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7423\n",
      "Iterating over 12572 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>My girlfriend told me she was admistres\n",
      "\n",
      "but I don't left hone my son's going to my wife<BOUND>\n",
      "***** Epoch 21 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:48<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7462\n",
      "Iterating over 12890 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Where do they have seen a grand scorile?\n",
      "\n",
      "A microwaver.<BOUND>\n",
      "***** Epoch 22 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:45<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7519\n",
      "Iterating over 13207 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What do you call a cow with no ones?\n",
      "\n",
      "a task about?<BOUND>\n",
      "***** Epoch 23 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:38<00:00,  8.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7579\n",
      "Iterating over 13504 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Whats the worst part of thing about Neu chines\n",
      "\n",
      "An old customer gives me a unwaired by its Predator.<BOUND>\n",
      "***** Epoch 24 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:44<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7952\n",
      "Iterating over 13782 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>How much does a feminist and a men and a doctor?\n",
      "\n",
      "Cathwere cleaned, then is a manciator <BOUND>\n",
      "***** Epoch 25 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:45<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7696\n",
      "Iterating over 14081 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A man is sitting on a crist for Candelan Soldier\n",
      "\n",
      "There were carrying one thigh weep, so they take two cars and bodyguarls. An emptile two father vacation to the car and asks them, dressed that she was against someone else, just sit up in his balls and so did together and blindering a piano and fly around the last late time. He thought \"Oh Bizey, logia, are a blonde really taxe!  He's ever more serious brasisting plant and make smaller people in the gym to my family. Hold on it, he's chooser, and more people's can imagine and it is the mom \"what do you say?\" The guy comes in on the window of denie. \"Mom, mommy, what was it testing him right at her options?!\" \"I know,\" she says, \"I HOT WANE OCERTEKIA DEIPESPERAK\". <BOUND>\n",
      "***** Epoch 26 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:47<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7757\n",
      "Iterating over 14337 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What shavs Fror the Yornes of The Witoos?\n",
      "\n",
      "Spalep <BOUND>\n",
      "***** Epoch 27 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:51<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7819\n",
      "Iterating over 14599 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>When if you used to give a pet account...\n",
      "\n",
      "Too bad people have found the room guys were explained tolerate. <BOUND>\n",
      "***** Epoch 28 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:44<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7999\n",
      "Iterating over 14860 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>How do you hospitals a racist joke?\n",
      "\n",
      "When his parents intercide. They always fell notea paddy.<BOUND>\n",
      "***** Epoch 29 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:44<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7880\n",
      "Iterating over 15139 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>An old man was simply raising his gang towards he risa...\n",
      "\n",
      "\n",
      "...hit his wife a spotter is even doing the house and complete his girlfriend and he uses them immediately. She asks her, \"Anymh, pay!\" \"Well,\" says the duck, \"I can clear you want to talk about you proposition.\"\n",
      "\n",
      "<BOUND>\n",
      "***** Epoch 30 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:45<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7874\n",
      "Iterating over 15406 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>A man finds a jan\n",
      "\n",
      "A group of stood barks in a hotel rush to tell in.\n",
      "\n",
      "He goes to talk to her husband, above the bar, and says, \"Hey, have all-tense Me tree that your week?\" \n",
      "\n",
      "The man reaches up to the bartender, shoots the place. He hands it opens a table in read his fare-neighborhan.  \n",
      "\n",
      "\"New my dad is my parents, whoreving, I graduated all night. I dream I was shot third mans to a miragin Butt. Have enough for me to come over in and I can't constantly receive, but therefore, sipping shit your wife.  He remember me to shoot the bear and family got him.\"\n",
      "\n",
      "\"Now, what a good girl?\"\n",
      "\n",
      "\"No\" answer so red\n",
      "gidgancy mumbling and stumbles back again.\n",
      "\n",
      "\"Good you can try it!\" Replies American...\n",
      "\n",
      "\"You sin, I said she is convinces and have a looked ote and say \"oh always thought you won't believe\" are now board. So he goes couldn't believe him, so he starts sweating the hut each pill on his face.\n",
      "\n",
      "After a few Marcham goes raising another apple. He ships out a lake. Grandpa cashier spoke before the\n",
      "***** Epoch 31 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:45<00:00,  8.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7922\n",
      "Iterating over 15640 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Wifease decided to say \"I have never falked with Fishing\".\n",
      "\n",
      "It was twin eye drive<BOUND>\n",
      "***** Epoch 32 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:48<00:00,  8.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.7979\n",
      "Iterating over 15898 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>What did the pat? ommeted leg in the chickens\n",
      "\n",
      "So I put it in.<BOUND>\n",
      "***** Epoch 33 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:32<00:00,  8.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8012\n",
      "Iterating over 16146 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Why are handicappets right next to like?\n",
      "\n",
      "Because the joke I got my old princess<BOUND>\n",
      "***** Epoch 34 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:37<00:00,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8247\n",
      "Iterating over 16404 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>So this man wants to jot: \"This isn't the restroom and told alpoates green..Utteen lady\n",
      "\n",
      "A man jumps out of the door and looks at me patient.  \"I'm going to call let me finish the Puba\n",
      "\n",
      "I fuck it glad.\"\n",
      "\n",
      "Then 10: PlEtene, and How Farre's best already sending them to scient their hands.\n",
      "\n",
      "Edta Blue preferscress a vegetable question hathered. To which bashed to cram into 590 million and sure enough to him. He had walking to her house and leaves him together. He explained that he is a tHurk, he could see the shit out of a turkey battle. The professor takes the turkey, lucks his winesar to the foarnets and says, \"I DON'T GOT SOCE CREAME is an hot-hanged is greet. He which is always right with all of you! He said it was too short me. I will improve it to my right towards the secret woolen I leave.\"\n",
      "\n",
      "The pastor yells, \"I told you not be able to tell the guys to just donate a quick who will try again. It's all seen for our son.\"\n",
      "\n",
      "The second prooldess to which the woman says,\"Hush, I think I - \n",
      "***** Epoch 35 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:33<00:00,  8.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8055\n",
      "Iterating over 16653 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Warn Engineering (love Americans are spending earhander on the bar.\n",
      "\n",
      "A woman walks in to to see the Jewish couples of Birds just under them.\n",
      "\n",
      "God sees through his new shoes and asked them to stand up\n",
      "\n",
      "The bartender replies, 'What the hell did you explain this time? \n",
      "\n",
      "Daddy, wratching places of some punch as he came out of the car  back of Torto. There were two millions and a man from inside.<BOUND>\n",
      "***** Epoch 36 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 250/250 [36:35<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss of 0.8082\n",
      "Iterating over 16885 documents\n",
      "***** EXAMPLE OUTPUT*****\n",
      "<BOUND>Did you know going to have Prime, but have never falls.\n",
      "\n",
      "Singiling a root scale weed literable.<BOUND>\n",
      "***** Epoch 37 *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▎                       | 176/250 [25:29<10:43,  8.69s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-5dc18bec61e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMONITOR_FREQ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mchar_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"char_indx_input\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mchar_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"topic_input\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopic_input\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;31m#now masking bit...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTOTAL_DEPTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2357\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#now a loop\n",
    "epoch = 0\n",
    "training_model.reset_states()\n",
    "#need initial ys...\n",
    "while True:\n",
    "    epoch+=1\n",
    "    print(\"***** Epoch {} *****\".format(epoch)) \n",
    "    loss = np.zeros(MONITOR_FREQ,dtype=np.float32)\n",
    "    for i in tqdm(range(MONITOR_FREQ)):\n",
    "        char_input, y, topic_input, state_mask = next(gen_seq)\n",
    "        loss[i] = training_model.train_on_batch(x={\"char_indx_input\":char_input, \"topic_input\":topic_input}, y=y)\n",
    "        #now masking bit...\n",
    "        for i in range(TOTAL_DEPTH):\n",
    "            reset_states(training_model, \"rnn\"+str(i), state_mask)\n",
    "    #checkpointer\n",
    "    training_model.save(\"models/\"+MODEL_NAME)\n",
    "    print(\"Average loss of {:.4f}\".format(np.mean(loss)))\n",
    "    print(\"Iterating over {} documents\".format(gen_seq.batch_size + len(gen_seq.available_idxs)))\n",
    "    print(\"***** EXAMPLE OUTPUT*****\")\n",
    "    predict_model.set_weights(training_model.get_weights())\n",
    "    joke = generate_joke(predict_model, generator_topic, char_dict, max_len=1000)\n",
    "    print(joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
